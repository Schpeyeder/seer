{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.0.53\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace, Experiment, Datastore\n",
    "from azureml.data.datapath import DataPath, DataPathComputeBinding\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.pipeline.core import Pipeline, PipelineData, PipelineParameter\n",
    "from azureml.pipeline.steps import PythonScriptStep, EstimatorStep\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register/Reference a Datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datastore = Datastore.register_azure_blob_container(workspace=ws, \n",
    "#                                             datastore_name='seerdata', \n",
    "#                                             container_name='your azure blob container name',\n",
    "#                                             account_name='your storage account name', \n",
    "#                                             account_key='your storage account key',\n",
    "#                                             create_if_not_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'workspacefilestore': <azureml.data.azure_storage_datastore.AzureFileDatastore at 0x2218148bba8>,\n",
       " 'workspaceblobstore': <azureml.data.azure_storage_datastore.AzureBlobDatastore at 0x221814c2cc0>,\n",
       " 'halworkspacestorage__datasets': <azureml.data.azure_storage_datastore.AzureBlobDatastore at 0x221814c2f98>,\n",
       " 'seerdata': <azureml.data.azure_storage_datastore.AzureBlobDatastore at 0x221814d0320>,\n",
       " 'halworkspacestorage__azureml_blobstore_12257f97_0fe1_48cf_b3e7_ba17edaed331': <azureml.data.azure_storage_datastore.AzureBlobDatastore at 0x221814d0630>}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# workspace\n",
    "ws = Workspace.from_config()\n",
    "ws.datastores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "datastore = ws.datastores['seerdata']\n",
    "\n",
    "# compute target\n",
    "compute = ws.compute_targets['gandalf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Pipeline!\n",
    "The following will be created and then run:\n",
    "1. Pipeline Parameters (path on datastore)\n",
    "2. Data Prep Step\n",
    "3. Training Step\n",
    "4. Model Registration Step\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Parameters\n",
    "We need to tell the Pipeline what it needs to learn to see!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = DataPath(datastore=datastore, path_on_datastore='burrito_tacos')\n",
    "data_path_pipeline_param = (PipelineParameter(name=\"data\", \n",
    "                                             default_value=datapath), \n",
    "                                             DataPathComputeBinding(mode='mount'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Process Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "seer_tfrecords = PipelineData(\n",
    "    \"tfrecords_set\",\n",
    "    datastore=datastore,\n",
    "    is_directory=True\n",
    ")\n",
    "\n",
    "prep = Estimator(source_directory='.',\n",
    "                      compute_target=compute,\n",
    "                      entry_script='parse.py',\n",
    "                      use_gpu=True,\n",
    "                      pip_requirements_file='requirements.txt')\n",
    "\n",
    "prepStep = EstimatorStep(\n",
    "    name='Data Preparation',\n",
    "    estimator=prep,\n",
    "    estimator_entry_script_arguments=[\"--source_path\", data_path_pipeline_param, \n",
    "                                      \"--target_path\", seer_tfrecords],\n",
    "    inputs=[data_path_pipeline_param],\n",
    "    outputs=[seer_tfrecords],\n",
    "    compute_target=compute\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "seer_training = PipelineData(\n",
    "    \"train\",\n",
    "    datastore=datastore,\n",
    "    is_directory=True\n",
    ")\n",
    "\n",
    "train = Estimator(source_directory='.',\n",
    "                      compute_target=compute,\n",
    "                      entry_script='train.py',\n",
    "                      use_gpu=True,\n",
    "                      pip_requirements_file='requirements.txt')\n",
    "\n",
    "trainStep = EstimatorStep(\n",
    "    name='Model Training',\n",
    "    estimator=train,\n",
    "    estimator_entry_script_arguments=[\"--source_path\", seer_tfrecords, \n",
    "                                      \"--target_path\", seer_training,\n",
    "                                      \"--epochs\", 5,\n",
    "                                      \"--batch\", 10,\n",
    "                                      \"--lr\", 0.001],\n",
    "    inputs=[seer_tfrecords],\n",
    "    outputs=[seer_training],\n",
    "    compute_target=compute\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register Model Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "seer_model = PipelineData(\n",
    "    \"model\",\n",
    "    datastore=datastore,\n",
    "    is_directory=True\n",
    ")\n",
    "\n",
    "register = Estimator(source_directory='.',\n",
    "                      compute_target=compute,\n",
    "                      entry_script='register.py',\n",
    "                      use_gpu=True)\n",
    "\n",
    "registerStep = EstimatorStep(\n",
    "    name='Model Registration',\n",
    "    estimator=register,\n",
    "    estimator_entry_script_arguments=[\"--source_path\", seer_training, \n",
    "                                      \"--target_path\", seer_model],\n",
    "    inputs=[seer_training],\n",
    "    outputs=[seer_model],\n",
    "    compute_target=compute\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline1 = Pipeline(workspace=ws, steps=[prepStep, trainStep, registerStep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step Data Preparation [bfc55750][5f72260c-c098-4fd6-9a71-66121ce82290], (This step will run and generate new outputs)\n",
      "Created step Model Training [ec4ed7d5][1da12d8a-aa42-4fc8-ba51-f780b6958d3e], (This step will run and generate new outputs)\n",
      "Created step Model Registration [8c804dee][8ba99f6a-d7a8-4f36-bd8b-996bc643fc40], (This step will run and generate new outputs)\n",
      "Created data reference seerdata_7b12afab for StepId [09590dec][8fc2591c-1e3f-4656-8a38-a3241d2a91c2], (Consumers of this data will generate new runs.)\n",
      "Submitted pipeline run: 1d139a7f-7697-48a3-97cd-03ea2e2bc95f\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d149730047b49c0891fe87b61cd6852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Submit the pipeline to be run\n",
    "pipeline_run1 = Experiment(ws, 'seer_next').submit(pipeline1)\n",
    "RunDetails(pipeline_run1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline_run1.cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_pipeline1 = pipeline1.publish(\n",
    "    name=\"Seer Pipeline (vNext)\", \n",
    "    description=\"Transfer learned image classifier. Uses folders as labels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
